{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ IBM Granite 3.2 Model Server for EchoVerse\n",
        "\n",
        "This notebook sets up IBM Granite 3.2 model as an API server for your EchoVerse project.\n",
        "\n",
        "## Instructions:\n",
        "1. Run all cells in order\n",
        "2. Copy the ngrok URL from the last cell\n",
        "3. Update your Flask app with this URL\n",
        "4. Keep this notebook running while using EchoVerse"
      ],
      "metadata": {
        "id": "setup_instructions"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install transformers torch accelerate bitsandbytes flask pyngrok requests\n",
        "!pip install huggingface_hub --upgrade"
      ],
      "metadata": {
        "id": "install_packages"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from flask import Flask, request, jsonify\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "import time\n",
        "import logging\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully!\")"
      ],
      "metadata": {
        "id": "import_libraries"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load IBM Granite 3.2 Model\n",
        "# Using ibm-granite/granite-3b-code-instruct (official IBM model)\n",
        "MODEL_NAME = \"ibm-granite/granite-3b-code-instruct\"  # Official IBM Granite model\n",
        "\n",
        "print(f\"üîÑ Loading model: {MODEL_NAME}\")\n",
        "\n",
        "# Configure quantization for memory efficiency\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\"\n",
        ")\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, padding_side=\"left\")\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Load model with quantization\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    quantization_config=quantization_config,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "print(\"‚úÖ IBM Granite 3.2 Model loaded successfully!\")\n",
        "print(f\"üìä Model device: {model.device}\")\n",
        "print(f\"üß† Model parameters: {model.num_parameters():,}\")"
      ],
      "metadata": {
        "id": "load_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define tone transformation prompts\n",
        "TONE_PROMPTS = {\n",
        "    \"neutral\": \"Rewrite the following text in a clear, neutral tone:\\n\\n{text}\\n\\nRewritten text:\",\n",
        "    \"suspenseful\": \"Transform this text into a suspenseful, mysterious narrative:\\n\\n{text}\\n\\nSuspenseful version:\",\n",
        "    \"dramatic\": \"Rewrite this text with dramatic flair and emotional intensity:\\n\\n{text}\\n\\nDramatic version:\",\n",
        "    \"inspiring\": \"Transform this text into an inspiring, motivational narrative:\\n\\n{text}\\n\\nInspiring version:\",\n",
        "    \"educational\": \"Rewrite this text in an educational, informative style:\\n\\n{text}\\n\\nEducational version:\",\n",
        "    \"conversational\": \"Transform this text into a friendly, conversational style:\\n\\n{text}\\n\\nConversational version:\",\n",
        "    \"formal\": \"Rewrite this text in a formal, professional tone:\\n\\n{text}\\n\\nFormal version:\",\n",
        "    \"calming\": \"Transform this text into a peaceful, calming narrative:\\n\\n{text}\\n\\nCalming version:\"\n",
        "}\n",
        "\n",
        "def transform_text(text, tone=\"neutral\"):\n",
        "    \"\"\"Transform text using IBM Granite model\"\"\"\n",
        "    try:\n",
        "        # Get prompt template\n",
        "        prompt = TONE_PROMPTS.get(tone, TONE_PROMPTS[\"neutral\"]).format(text=text)\n",
        "        \n",
        "        # Tokenize input\n",
        "        inputs = tokenizer(\n",
        "            prompt,\n",
        "            return_tensors=\"pt\",\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            padding=True\n",
        "        ).to(model.device)\n",
        "        \n",
        "        # Generate response\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=200,\n",
        "                temperature=0.7,\n",
        "                do_sample=True,\n",
        "                pad_token_id=tokenizer.pad_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id\n",
        "            )\n",
        "        \n",
        "        # Decode response\n",
        "        generated_text = tokenizer.decode(\n",
        "            outputs[0][inputs['input_ids'].shape[1]:],\n",
        "            skip_special_tokens=True\n",
        "        ).strip()\n",
        "        \n",
        "        # Clean up response\n",
        "        if generated_text:\n",
        "            # Take first meaningful sentence\n",
        "            sentences = generated_text.split('.')\n",
        "            cleaned = sentences[0].strip() if sentences else generated_text\n",
        "            return cleaned if len(cleaned) > 10 else text\n",
        "        else:\n",
        "            return text\n",
        "            \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in text transformation: {str(e)}\")\n",
        "        return text\n",
        "\n",
        "print(\"‚úÖ Text transformation function ready!\")"
      ],
      "metadata": {
        "id": "define_functions"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Flask API server\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/health', methods=['GET'])\n",
        "def health_check():\n",
        "    \"\"\"Health check endpoint\"\"\"\n",
        "    return jsonify({\n",
        "        'status': 'healthy',\n",
        "        'model': MODEL_NAME,\n",
        "        'device': str(model.device),\n",
        "        'message': 'IBM Granite Model Server is running!'\n",
        "    })\n",
        "\n",
        "@app.route('/transform', methods=['POST'])\n",
        "def api_transform_text():\n",
        "    \"\"\"Transform text with specified tone\"\"\"\n",
        "    try:\n",
        "        data = request.get_json()\n",
        "        text = data.get('text', '')\n",
        "        tone = data.get('tone', 'neutral')\n",
        "        \n",
        "        if not text.strip():\n",
        "            return jsonify({'error': 'Text is required'}), 400\n",
        "        \n",
        "        # Transform text\n",
        "        transformed_text = transform_text(text, tone)\n",
        "        \n",
        "        return jsonify({\n",
        "            'status': 'success',\n",
        "            'original_text': text,\n",
        "            'transformed_text': transformed_text,\n",
        "            'tone': tone,\n",
        "            'model': MODEL_NAME\n",
        "        })\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.error(f\"API Error: {str(e)}\")\n",
        "        return jsonify({'error': str(e)}), 500\n",
        "\n",
        "@app.route('/available-tones', methods=['GET'])\n",
        "def get_available_tones():\n",
        "    \"\"\"Get list of available tones\"\"\"\n",
        "    return jsonify({\n",
        "        'tones': list(TONE_PROMPTS.keys()),\n",
        "        'count': len(TONE_PROMPTS)\n",
        "    })\n",
        "\n",
        "print(\"‚úÖ Flask API server created!\")"
      ],
      "metadata": {
        "id": "create_api"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup ngrok tunnel\n",
        "# Get your free ngrok token from: https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "NGROK_TOKEN = \"YOUR_NGROK_TOKEN_HERE\"  # Replace with your actual token\n",
        "\n",
        "# Uncomment and set your ngrok token\n",
        "# ngrok.set_auth_token(NGROK_TOKEN)\n",
        "\n",
        "# For now, we'll run without authentication (limited time)\n",
        "print(\"‚ö†Ô∏è  Running without ngrok authentication (limited time)\")\n",
        "print(\"üí° Get free token from: https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
        "\n",
        "# Start ngrok tunnel\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"\\nüåê IBM Granite Model Server is now accessible at:\")\n",
        "print(f\"üì° Public URL: {public_url}\")\n",
        "print(f\"\\nüìã Copy this URL and update your Flask app configuration!\")\n",
        "print(f\"\\nüîó API Endpoints:\")\n",
        "print(f\"   Health Check: {public_url}/health\")\n",
        "print(f\"   Transform Text: {public_url}/transform\")\n",
        "print(f\"   Available Tones: {public_url}/available-tones\")"
      ],
      "metadata": {
        "id": "setup_ngrok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start the Flask server\n",
        "def run_server():\n",
        "    app.run(host='0.0.0.0', port=5000, debug=False)\n",
        "\n",
        "# Start server in background thread\n",
        "server_thread = threading.Thread(target=run_server)\n",
        "server_thread.daemon = True\n",
        "server_thread.start()\n",
        "\n",
        "print(\"üöÄ IBM Granite Model Server is now running!\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéØ IMPORTANT: Copy the ngrok URL above and update your Flask app!\")\n",
        "print(\"üìù Update GRANITE_API_URL in your Flask configuration\")\n",
        "print(\"‚è∞ Keep this notebook running while using EchoVerse\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Keep the notebook running\n",
        "try:\n",
        "    while True:\n",
        "        time.sleep(60)\n",
        "        print(f\"‚è∞ Server running... {time.strftime('%H:%M:%S')}\")\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nüõë Server stopped by user\")"
      ],
      "metadata": {
        "id": "start_server"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
